# GCS-Infra-Live ES -> [EN](README.en.md)

## Infra Apply + Ansible (post-apply) en rama main

Este documento resume los cambios realizados en main para ejecutar configuraciones de Ansible de forma segura despuÃ©s del terraform apply, usando `OS Login + IAP` (sin llaves SSH ni puerto 22 pÃºblico) y un inventario generado `on-the-fly.`

## QuÃ© se aÃ±adiÃ³
### 1) Workflow encadenado: Inventory-And-Ansible.yaml
* UbicaciÃ³n: `.github/workflows/Inventory-And-Ansible.yaml`
* Se dispara automÃ¡ticamente cuando el workflow `terraform-apply` finaliza con Ã©xito.
* Hace 3 jobs separados (visibilidad â€œproâ€ en Actions):
   #### *1) generate_inventory*
     * Autentica en GCP vÃ­a OIDC.
     * Genera ansible/hosts.ini con las VMs RUNNING que tengan `labels.env=entorno (por defecto dev)`.
     * Crea `ansible/ansible.cfg` apuntando a `~/.ssh/config (gcloud + IAP)`.
     * Verifica que el inventario no contenga IPs (solo FQDN GCE).
     * Sube ambos ficheros como `artifact: ansible-inventory-env`.
   #### *2) publish_inventory*
     * Publica/eco del artifact listo (opcional, solo visibilidad).
   #### *3) run_ansible*
     * Descarga el artifact en `ansible/.`
     * Instala Ansible.
     * Ejecuta `ansible-playbook ansible/site.yml` usando `ANSIBLE_CONFIG=ansible/ansible.cfg`.  


#### Si queremos cubrir prod, aÃ±adimos prod a la matrix.env en los tres jobs.
---

### 2) Playbook mÃ­nimo de Ansible: ansible/site.yml
* Crea la estructura de carpetas en la VM bajo `/opt/monitoring`.
* Copia (si existen en el repo) los archivos de `Prometheus, Alertmanager, Grafana y Docker` hacia la VM.
---
## Requisitos

### Variables de repositorio (Settings â†’ Variables)
* `GCP_WORKLOAD_IDENTITY_PROVIDER (WIF)`
* `GCP_SERVICE_ACCOUNT` (SA usado por OIDC)

### IAM necesarias para el identity que ejecuta los workflows
* `roles/compute.osAdminLogin` (o roles/compute.osLogin si no se necesita sudo)
* `roles/iap.tunnelResourceAccessor`

### Red/Firewall
* SSH solo por `IAP`
* OS Login activado (a nivel proyecto y/o VM): `enable-oslogin = TRUE`.

### Etiquetas
* Las VMs que deben entrar en el inventario deben tener `labels.env=dev` (o el entorno que se use).

## Estructura recomendada del repositorio (En proceso)
```bash
ansible/
  site.yml
  requirements.yml
  web/
    index.html
    style.css
  files/
    monitoring/
      docker/
        docker-compose.yml            # (Ya puesto)
      prometheus/
        prometheus.yml                # (ya puesto)
        rules/
          alerts.yml                  # (ya puesto)
      grafana/
        provisioning/
          datasources/
            datasource.yml            # (ya puesto)
          dashboards/
            ejemplo.json              # (ya puesto)
      template/
        monitoring/
          alertmanager.yml.j2         # (Plantilla que generara el Alertmanager.yml)s
```
---
## CÃ³mo funciona el pipeline completo
1. Se hace merge a main y corre el `terraform-apply` (con revisiÃ³n del environment si procede).
2. Al terminar OK, se lanza `inventory-and-ansible`:
   * **Job 1:** genera inventario por etiquetas y sube artifact.
   * **Job 2:** marca visibilidad del artifact (opcional).
   * **Job 3:** descarga el artifact en `ansible/` e invoca `ansible-playbook` contra tus hosts.
   * **Job 4:** Instala la coleccion necesaria de Ansible `community.docker`.

3. Despues de la ejecucion del pipeline `inventory-and-ansible`.

   - Instala Docker y el plugin de Docker Compose en la VM.
   - Copia el stack de monitoring a `/opt/monitoring`.
   - Renderiza la configuraciÃ³n de Alertmanager desde una plantilla usando **GitHub Secrets**.
   - Levanta (o actualiza) el stack con `docker compose` de forma idempotente.

## Estructura de carpetas en la VM

```makefile
- `/opt/monitoring`
  - `docker-compose.yml` (Prometheus, Alertmanager, Grafana, Blackbox, node-exporter, web)
  - `prometheus/`
    - `prometheus.yml`
    - `rules/alerts.yml`
  - `alertmanager/`
    - `alertmanager.yml`
  - `grafana/`
    - provisioning, datasources, dashboards, etc.
- `/opt/web01`
  - `index.html`
  - `styles.css`
  - (cualquier otro estÃ¡tico de la pÃ¡gina)
```


## Stack desplegado:

- `prometheus`
- `alertmanager`
- `node-exporter`
- `web (hosting simple)`
- `grafana` (con datasource de Prometheus preconfigurado)
- Reglas de alertas bÃ¡sicas + salud del host
- Alertas enviadas por correo vÃ­a Alertmanager

## Ansible site.yml

El playbook encargado de:

1. Instalar Docker + plugin de compose.

2. Crear directorios:
   * `monitoring_base_dir: /opt/monitoring`
   * `web01_base_dir: /opt/web01`

3. Copiar:
   * `docker-compose.yml` y ficheros de Prometheus, Alertmanager y Grafana a `/opt/monitoring`.
   * Contenido de `files/web/` (HTML/CSS) a `/opt/web01`.

4. Levantar o actualizar el stack:
```yaml
community.docker.docker_compose_v2:
  project_src: "{{ monitoring_base_dir }}"
  state: present
  remove_orphans: true
```
Cuando cambian los archivos de la web o del stack, se notifica al handler `restart monitoring stack` para recrear los contenedores.

## ðŸ³ Stack Docker: docker-compose.yml

Servicios desplegados en el `docker-compose.yml`

Ruta: `ansible/files/monitoring/docker/docker-compose.yml`.

* `prometheus` -> recolecta mÃ©tricas 
* `alertmanager` -> gestiona las alertas
* `node-exporter` -> mÃ©tricas de sistema (CPU, RAM, disco, red)
* `grafana` -> visualizacion de metricas
* `web (Nginx)` -> sirve la web estÃ¡tica desde `/opt/web01` 
* `blackbox` -> Comprueba la disponibilidad HTTP de la web

## Redes Docker

* `monitoring` -> prometheus, Grafana, Alertmanager, node-exporter, blackbox.

* `web-01` -> Nginx (`web`) + blackbox (para poder sondear `http://web:80`).

El servicio `web` monta:

```yaml
volumes:
  - /opt/web01:/usr/share/nginx/html:ro
  ```  

## ðŸ“Š Prometheus: prometheus.yml + reglas

Ruta: `ansible/files/monitoring/prometheus/prometheus.yml`.

Scrapea:

* prometheus:9090

* alertmanager:9093

* node-exporter:9100

Carga reglas desde `/etc/prometheus/rules/*.yml`.

***EnvÃ­a alertas a Alertmanager.***

### Reglas de alertas

Ruta: `ansible/files/monitoring/prometheus/rules/alerts.yml`.

Incluye dos grupos de reglas:

* `infra_basic`: estado general de targets, Prometheus y Alertmanager.
* `host_health`: salud del host basada en mÃ©tricas de `node_exporter` (**CPU**, **memoria**, **disco**, **filesystem read-only**, etc.).

* Ademas de aÃ±adir `blackbox` para la monitorizacion de la pagina web.  
   * blackbox interno:  
     * Target: `http://web:80`  
   * blackbox externo o publico(Cuando haya dominio + cloudflare):  
     * Target: `https://Nuestro-dominio.com`  

Ambos jobs usan `relabel_configs` para enviar las peticiones al `blackbox-exporter` en `blackbox:9115`.

## ðŸ“ˆ Grafana: datasource provisioning

Ruta: `ansible/files/monitoring/grafana/provisioning/datasources/datasource.yml`.

Datasource de Prometheus creado automÃ¡ticamente al arrancar Grafana.

## ðŸ“¬ Alertmanager: plantilla con SMTP y GitHub Secrets

Ruta: `ansible/templates/monitoring/alertmanager.yml.j2`

Alertmanager se configura a partir de una plantilla Jinja2.

Las credenciales SMTP se inyectan desde GitHub Secrets en el workflow de Ansible:

### Secrets en GitHub necesarios  
En Settings â†’ `Secrets and variables` â†’ `Actions`:

* `ALERT_SMTP_SMARTHOST` â†’ ej. smtp.gmail.com:587

* `ALERT_SMTP_FROM` â†’ correo remitente

* `ALERT_SMTP_USER` â†’ usuario SMTP (normalmente el mismo correo)

* `ALERT_SMTP_PASS` â†’ contraseÃ±a de aplicaciÃ³n del proveedor de correo

* `ALERT_SMTP_TO` â†’ correo destino (si se omite, usa ALERT_SMTP_FROM)

El step de Ansible en el workflow pasa estos secrets al playbook como variables -e, que la plantilla usa para generar `alertmanager.yml` en la VM.

## Web estÃ¡tica

* Nginx sirve una pÃ¡gina simple de portfolio/explicacion del proyecto:
   * Descripcion de la infraestructura (Terraform + GCP + Github Action + Ansible + Docker)
   * Embeds de video de youtube mostrando el Bootstrap/repo-Live de la infraestructura
   * Enlaces a los repositorios de ***Bootstrap*** y ***Infra-Live***
* El contenido HTML/CSS vive en el repo bajo `ansible/web` y se copia a `/opt/web01` mediante Ansible.

## ValidacÃ­on local (WSL)

Herramientas usadas para validar la configuracion antes de desplegar:

*  Ansible  
   * `ansible-playbook site.yml --syntax-check`

* Prometheus
   * `promtool check config files/monitoring/prometheus/prometheus.yml`
   * `promtool check rules files/monitoring/prometheus/rules/alerts.yml`

* Docker-compose
   * `docker-compose config` (desde `files/monitoring/docker`)

* YAML linting
   * `yamllint` sobre `prometheus.yml` y `alerts.yml` para limpiar espacios y comentarios

## Artefacts y visibilidad
* Inventario y cfg quedan guardados como artifact:  
`ansible-inventory-env` â†’ `ansible/hosts.ini`, `ansible/ansible.cfg`

* Puedes descargarlo desde la pestaÃ±a ***Actions*** del run correspondiente.

## Buenas prÃ¡cticas que hemos seguido
* Sin llaves SSH ni 22 pÃºblico: acceso por OS Login + IAP.
* Inventario efÃ­mero (on-the-fly) y sin IPs (solo FQDN GCE).
* Concurrencia en el workflow para evitar solapes.
* Jobs separados para mÃ¡xima visibilidad (generate â†’ publish â†’ apply).

